{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Exam5-thang","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNN85HfNLFO9AxAAr/+Z/LI"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"tEXwDqPPyGm7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1595127335207,"user_tz":-540,"elapsed":371238,"user":{"displayName":"Duc Thang Luu","photoUrl":"https://lh6.googleusercontent.com/-9pv_MaomS7I/AAAAAAAAAAI/AAAAAAAAAf4/nNDEccmr_7w/s64/photo.jpg","userId":"11920885927812896586"}},"outputId":"ad5c4d9d-2415-4beb-ddfa-b7329e6d824f"},"source":["# ======================================================================\n","# There are 5 questions in this exam with increasing difficulty from 1-5.\n","# Please note that the weight of the grade for the question is relative\n","# to its difficulty. So your Category 1 question will score significantly\n","# less than your Category 5 question.\n","#\n","# Don't use lambda layers in your model.\n","# You do not need them to solve the question.\n","# Lambda layers are not supported by the grading infrastructure.\n","#\n","# You must use the Submit and Test button to submit your model\n","# at least once in this category before you finally submit your exam,\n","# otherwise you will score zero for this category.\n","# ======================================================================\n","# QUESTION\n","#\n","# Build and train a neural network to predict sunspot activity using\n","# the Sunspots.csv dataset.\n","#\n","# Your neural network must have an MAE of 0.12 or less on the normalized dataset\n","# for top marks.\n","#\n","# Code for normalizing the data is provided and should not be changed.\n","#\n","# At the bottom of this file, we provide  some testing\n","# code in case you want to check your model.\n","\n","# Note: Do not use lambda layers in your model, they are not supported\n","# on the grading infrastructure.\n","\n","\n","import csv\n","import tensorflow as tf\n","import numpy as np\n","import urllib\n","\n","# DO NOT CHANGE THIS CODE\n","def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n","    series = tf.expand_dims(series, axis=-1)\n","    ds = tf.data.Dataset.from_tensor_slices(series)\n","    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n","    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n","    ds = ds.shuffle(shuffle_buffer)\n","    ds = ds.map(lambda w: (w[:-1], w[1:]))\n","    return ds.batch(batch_size).prefetch(1)\n","\n","\n","def solution_model():\n","    url = 'https://storage.googleapis.com/download.tensorflow.org/data/Sunspots.csv'\n","    urllib.request.urlretrieve(url, 'sunspots.csv')\n","\n","    time_step = []\n","    sunspots = []\n","\n","    with open('sunspots.csv') as csvfile:\n","        # YOUR CODE HERE\n","        reader = csv.reader(csvfile, delimiter=',')\n","        next(reader)\n","        for row in reader:\n","          sunspots.append(float(row[2]))\n","          time_step.append(int(row[0]))\n","\n","    series = np.array(sunspots)\n","    time = np.array(time_step)\n","\n","    # DO NOT CHANGE THIS CODE\n","    # This is the normalization function\n","    min = np.min(series)\n","    max = np.max(series)\n","    series -= min\n","    series /= max\n","    time = np.array(time_step)\n","\n","    # The data should be split into training and validation sets at time step 3000\n","    # DO NOT CHANGE THIS CODE\n","    split_time = 3000\n","    time_train = time[:split_time]\n","    x_train = series[:split_time]\n","    time_valid = time[split_time:]\n","    x_valid = series[split_time:]\n","\n","    # DO NOT CHANGE THIS CODE\n","    window_size = 30\n","    batch_size = 32\n","    shuffle_buffer_size = 1000\n","\n","\n","    train_set = windowed_dataset(x_train, window_size=window_size, batch_size=batch_size, shuffle_buffer=shuffle_buffer_size)\n","\n","\n","    model = tf.keras.models.Sequential([\n","      # YOUR CODE HERE. Whatever your first layer is, the input shape will be [None,1] when using the Windowed_dataset above, depending on the layer type chosen\n","      tf.keras.layers.Conv1D(filters=32, kernel_size=5,\n","                      strides=1, padding=\"causal\",\n","                      activation=\"relu\",\n","                      input_shape=[None, 1]),\n","      tf.keras.layers.LSTM(64, return_sequences=True),\n","      tf.keras.layers.LSTM(64, return_sequences=True),\n","      tf.keras.layers.Dense(30, activation=\"relu\"),\n","      tf.keras.layers.Dense(10, activation=\"relu\"),\n","      tf.keras.layers.Dense(1),\n","      # tf.keras.layers.Lambda(lambda x: x * 400)\n","    ])\n","    # model = tf.keras.models.Sequential([\n","    #   # DO NOT CHANGE THE FINAL TWO LAYERS FROM BELOW\n","    #   tf.keras.layers.Conv1D(filters=32, kernel_size=5,\n","    #                   strides=1, padding=\"causal\",\n","    #                   activation=\"relu\",\n","    #                   input_shape=[None, 1]),\n","    #   tf.keras.layers.LSTM(64, return_sequences=True),\n","    #   tf.keras.layers.LSTM(64, return_sequences=True),\n","    #   tf.keras.layers.Dense(30, activation=\"relu\"),\n","    #   tf.keras.layers.Dense(10, activation=\"relu\"),\n","    #   tf.keras.layers.Dense(1),\n","    #   tf.keras.layers.Lambda(lambda x: x * 400)\n","    # ])\n","    # PLEASE NOTE IF YOU SEE THIS TEXT WHILE TRAINING -- IT IS SAFE TO IGNORE\n","    # BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n","    # \t [[{{node IteratorGetNext}}]]\n","    #\n","    train_set = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)\n","    optimizer = tf.keras.optimizers.SGD(lr=1e-5, momentum=0.9)\n","    model.compile(loss=tf.keras.losses.Huber(),\n","              optimizer=optimizer,\n","              metrics=[\"mae\"])\n","    model.fit(train_set, epochs=100)\n","\n","\n","    # YOUR CODE HERE TO COMPILE AND TRAIN THE MODEL\n","    return model\n","\n","\n","# Note that you'll need to save your model as a .h5 like this.\n","# When you press the Submit and Test button, your saved .h5 model will\n","# be sent to the testing infrastructure for scoring\n","# and the score will be returned to you.\n","if __name__ == '__main__':\n","    model = solution_model()\n","    model.save(\"mymodel.h5\")\n","\n","\n","\n","# THIS CODE IS USED IN THE TESTER FOR FORECASTING. IF YOU WANT TO TEST YOUR MODEL\n","# BEFORE UPLOADING YOU CAN DO IT WITH THIS\n","#def model_forecast(model, series, window_size):\n","#    ds = tf.data.Dataset.from_tensor_slices(series)\n","#    ds = ds.window(window_size, shift=1, drop_remainder=True)\n","#    ds = ds.flat_map(lambda w: w.batch(window_size))\n","#    ds = ds.batch(32).prefetch(1)\n","#    forecast = model.predict(ds)\n","#    return forecast\n","\n","\n","#window_size = # YOUR CODE HERE\n","#rnn_forecast = model_forecast(model, series[..., np.newaxis], window_size)\n","#rnn_forecast = rnn_forecast[split_time - window_size:-1, -1, 0]\n","\n","#result = tf.keras.metrics.mean_absolute_error(x_valid, rnn_forecast).numpy()\n","\n","## To get the maximum score, your model must have an MAE OF .12 or less.\n","## When you Submit and Test your model, the grading infrastructure\n","## converts the MAE of your model to a score from 0 to 5 as follows:\n","\n","#test_val = 100 * result\n","#score = math.ceil(17 - test_val)\n","#if score > 5:\n","#    score = 5\n","\n","#print(score)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","93/93 [==============================] - 4s 38ms/step - loss: 0.0369 - mae: 0.2091\n","Epoch 2/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0359 - mae: 0.2048\n","Epoch 3/100\n","93/93 [==============================] - 4s 38ms/step - loss: 0.0350 - mae: 0.2009\n","Epoch 4/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0342 - mae: 0.1975\n","Epoch 5/100\n","93/93 [==============================] - 4s 39ms/step - loss: 0.0334 - mae: 0.1943\n","Epoch 6/100\n","93/93 [==============================] - 4s 38ms/step - loss: 0.0327 - mae: 0.1913\n","Epoch 7/100\n","93/93 [==============================] - 4s 39ms/step - loss: 0.0320 - mae: 0.1886\n","Epoch 8/100\n","93/93 [==============================] - 4s 39ms/step - loss: 0.0314 - mae: 0.1860\n","Epoch 9/100\n","93/93 [==============================] - 4s 38ms/step - loss: 0.0308 - mae: 0.1836\n","Epoch 10/100\n","93/93 [==============================] - 4s 38ms/step - loss: 0.0302 - mae: 0.1814\n","Epoch 11/100\n","93/93 [==============================] - 4s 38ms/step - loss: 0.0297 - mae: 0.1792\n","Epoch 12/100\n","93/93 [==============================] - 3s 38ms/step - loss: 0.0292 - mae: 0.1772\n","Epoch 13/100\n","93/93 [==============================] - 3s 38ms/step - loss: 0.0287 - mae: 0.1752\n","Epoch 14/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0282 - mae: 0.1734\n","Epoch 15/100\n","93/93 [==============================] - 4s 38ms/step - loss: 0.0278 - mae: 0.1716\n","Epoch 16/100\n","93/93 [==============================] - 3s 38ms/step - loss: 0.0274 - mae: 0.1700\n","Epoch 17/100\n","93/93 [==============================] - 3s 38ms/step - loss: 0.0269 - mae: 0.1684\n","Epoch 18/100\n","93/93 [==============================] - 4s 41ms/step - loss: 0.0265 - mae: 0.1669\n","Epoch 19/100\n","93/93 [==============================] - 4s 43ms/step - loss: 0.0262 - mae: 0.1654\n","Epoch 20/100\n","93/93 [==============================] - 4s 42ms/step - loss: 0.0258 - mae: 0.1640\n","Epoch 21/100\n","93/93 [==============================] - 4s 42ms/step - loss: 0.0254 - mae: 0.1627\n","Epoch 22/100\n","93/93 [==============================] - 4s 42ms/step - loss: 0.0251 - mae: 0.1614\n","Epoch 23/100\n","93/93 [==============================] - 4s 40ms/step - loss: 0.0247 - mae: 0.1602\n","Epoch 24/100\n","93/93 [==============================] - 4s 38ms/step - loss: 0.0244 - mae: 0.1591\n","Epoch 25/100\n","93/93 [==============================] - 4s 38ms/step - loss: 0.0241 - mae: 0.1580\n","Epoch 26/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0238 - mae: 0.1569\n","Epoch 27/100\n","93/93 [==============================] - 4s 39ms/step - loss: 0.0235 - mae: 0.1558\n","Epoch 28/100\n","93/93 [==============================] - 4s 38ms/step - loss: 0.0232 - mae: 0.1548\n","Epoch 29/100\n","93/93 [==============================] - 4s 39ms/step - loss: 0.0229 - mae: 0.1539\n","Epoch 30/100\n","93/93 [==============================] - 4s 38ms/step - loss: 0.0226 - mae: 0.1529\n","Epoch 31/100\n","93/93 [==============================] - 4s 38ms/step - loss: 0.0224 - mae: 0.1520\n","Epoch 32/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0221 - mae: 0.1511\n","Epoch 33/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0219 - mae: 0.1503\n","Epoch 34/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0216 - mae: 0.1495\n","Epoch 35/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0214 - mae: 0.1487\n","Epoch 36/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0212 - mae: 0.1480\n","Epoch 37/100\n","93/93 [==============================] - 4s 38ms/step - loss: 0.0210 - mae: 0.1473\n","Epoch 38/100\n","93/93 [==============================] - 4s 38ms/step - loss: 0.0207 - mae: 0.1466\n","Epoch 39/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0205 - mae: 0.1459\n","Epoch 40/100\n","93/93 [==============================] - 4s 38ms/step - loss: 0.0203 - mae: 0.1453\n","Epoch 41/100\n","93/93 [==============================] - 4s 38ms/step - loss: 0.0201 - mae: 0.1447\n","Epoch 42/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0200 - mae: 0.1441\n","Epoch 43/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0198 - mae: 0.1435\n","Epoch 44/100\n","93/93 [==============================] - 4s 38ms/step - loss: 0.0196 - mae: 0.1430\n","Epoch 45/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0194 - mae: 0.1424\n","Epoch 46/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0193 - mae: 0.1419\n","Epoch 47/100\n","93/93 [==============================] - 4s 38ms/step - loss: 0.0191 - mae: 0.1414\n","Epoch 48/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0189 - mae: 0.1409\n","Epoch 49/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0188 - mae: 0.1405\n","Epoch 50/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0186 - mae: 0.1400\n","Epoch 51/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0185 - mae: 0.1396\n","Epoch 52/100\n","93/93 [==============================] - 3s 38ms/step - loss: 0.0184 - mae: 0.1392\n","Epoch 53/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0182 - mae: 0.1388\n","Epoch 54/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0181 - mae: 0.1385\n","Epoch 55/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0180 - mae: 0.1381\n","Epoch 56/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0178 - mae: 0.1378\n","Epoch 57/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0177 - mae: 0.1375\n","Epoch 58/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0176 - mae: 0.1371\n","Epoch 59/100\n","93/93 [==============================] - 3s 38ms/step - loss: 0.0175 - mae: 0.1368\n","Epoch 60/100\n","93/93 [==============================] - 3s 36ms/step - loss: 0.0174 - mae: 0.1365\n","Epoch 61/100\n","93/93 [==============================] - 3s 36ms/step - loss: 0.0173 - mae: 0.1363\n","Epoch 62/100\n","93/93 [==============================] - 3s 36ms/step - loss: 0.0172 - mae: 0.1360\n","Epoch 63/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0171 - mae: 0.1357\n","Epoch 64/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0170 - mae: 0.1355\n","Epoch 65/100\n","93/93 [==============================] - 3s 36ms/step - loss: 0.0169 - mae: 0.1352\n","Epoch 66/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0168 - mae: 0.1350\n","Epoch 67/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0167 - mae: 0.1348\n","Epoch 68/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0166 - mae: 0.1346\n","Epoch 69/100\n","93/93 [==============================] - 3s 36ms/step - loss: 0.0165 - mae: 0.1344\n","Epoch 70/100\n","93/93 [==============================] - 3s 36ms/step - loss: 0.0164 - mae: 0.1342\n","Epoch 71/100\n","93/93 [==============================] - 3s 36ms/step - loss: 0.0163 - mae: 0.1340\n","Epoch 72/100\n","93/93 [==============================] - 3s 36ms/step - loss: 0.0163 - mae: 0.1338\n","Epoch 73/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0162 - mae: 0.1336\n","Epoch 74/100\n","93/93 [==============================] - 4s 38ms/step - loss: 0.0161 - mae: 0.1335\n","Epoch 75/100\n","93/93 [==============================] - 4s 38ms/step - loss: 0.0160 - mae: 0.1333\n","Epoch 76/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0160 - mae: 0.1331\n","Epoch 77/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0159 - mae: 0.1330\n","Epoch 78/100\n","93/93 [==============================] - 3s 36ms/step - loss: 0.0158 - mae: 0.1328\n","Epoch 79/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0158 - mae: 0.1327\n","Epoch 80/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0157 - mae: 0.1326\n","Epoch 81/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0156 - mae: 0.1325\n","Epoch 82/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0156 - mae: 0.1323\n","Epoch 83/100\n","93/93 [==============================] - 3s 36ms/step - loss: 0.0155 - mae: 0.1322\n","Epoch 84/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0155 - mae: 0.1321\n","Epoch 85/100\n","93/93 [==============================] - 3s 36ms/step - loss: 0.0154 - mae: 0.1320\n","Epoch 86/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0154 - mae: 0.1319\n","Epoch 87/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0153 - mae: 0.1318\n","Epoch 88/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0153 - mae: 0.1317\n","Epoch 89/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0152 - mae: 0.1316\n","Epoch 90/100\n","93/93 [==============================] - 4s 38ms/step - loss: 0.0152 - mae: 0.1315\n","Epoch 91/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0151 - mae: 0.1314\n","Epoch 92/100\n","93/93 [==============================] - 3s 38ms/step - loss: 0.0151 - mae: 0.1313\n","Epoch 93/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0150 - mae: 0.1313\n","Epoch 94/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0150 - mae: 0.1312\n","Epoch 95/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0149 - mae: 0.1311\n","Epoch 96/100\n","93/93 [==============================] - 5s 51ms/step - loss: 0.0149 - mae: 0.1310\n","Epoch 97/100\n","93/93 [==============================] - 6s 62ms/step - loss: 0.0149 - mae: 0.1310\n","Epoch 98/100\n","93/93 [==============================] - 4s 41ms/step - loss: 0.0148 - mae: 0.1309\n","Epoch 99/100\n","93/93 [==============================] - 3s 37ms/step - loss: 0.0148 - mae: 0.1308\n","Epoch 100/100\n","93/93 [==============================] - 4s 38ms/step - loss: 0.0147 - mae: 0.1308\n"],"name":"stdout"}]}]}