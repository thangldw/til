{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Exam4-thang","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"zArjSM5Qx47V","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1595133643392,"user_tz":-540,"elapsed":35,"user":{"displayName":"cong le","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyU4J69Q1Wa1yvFcxM5SYhxFbEMyJge79C_Pf2GQ=s64","userId":"16902361027910566800"}},"outputId":"980ded7d-1ffb-4973-ebd7-c6c0293bbc51"},"source":["# ======================================================================\n","# There are 5 questions in this exam with increasing difficulty from 1-5.\n","# Please note that the weight of the grade for the question is relative\n","# to its difficulty. So your Category 1 question will score significantly\n","# less than your Category 5 question.\n","#\n","# Don't use lambda layers in your model.\n","# You do not need them to solve the question.\n","# Lambda layers are not supported by the grading infrastructure.\n","#\n","# You must use the Submit and Test button to submit your model\n","# at least once in this category before you finally submit your exam,\n","# otherwise you will score zero for this category.\n","# ======================================================================\n","#\n","# NLP QUESTION\n","#\n","# Build and train a classifier for the sarcasm dataset.\n","# The classifier should have a final layer with 1 neuron activated by sigmoid as shown.\n","# It will be tested against a number of sentences that the network hasn't previously seen\n","# and you will be scored on whether sarcasm was correctly detected in those sentences.\n","\n","import json\n","import tensorflow as tf\n","import numpy as np\n","import urllib\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","\n","def solution_model():\n","    url = 'https://storage.googleapis.com/download.tensorflow.org/data/sarcasm.json'\n","    urllib.request.urlretrieve(url, 'sarcasm.json')\n","\n","    with open(\"./sarcasm.json\", 'r') as f:\n","        datastore = json.load(f)\n","\n","    # DO NOT CHANGE THIS CODE OR THE TESTS MAY NOT WORK\n","    vocab_size = 1000\n","    embedding_dim = 16\n","    max_length = 120\n","    trunc_type='post'\n","    padding_type='post'\n","    oov_tok = \"<OOV>\"\n","    training_size = 20000\n","\n","    sentences = []\n","    labels = []\n","    # YOUR CODE HERE\n","\n","    for item in datastore:\n","        sentences.append(item['headline'])\n","        labels.append(item['is_sarcastic'])\n","\n","    training_sentences = sentences[0:training_size]\n","    testing_sentences = sentences[training_size:]\n","    training_labels = labels[0:training_size]\n","    testing_labels = labels[training_size:]\n","\n","    tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n","    tokenizer.fit_on_texts(training_sentences)\n","\n","    word_index = tokenizer.word_index\n","\n","    training_sequences = tokenizer.texts_to_sequences(training_sentences)\n","    training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n","    testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n","    testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n","\n","    training_padded = np.array(training_padded)\n","    training_labels = np.array(training_labels)\n","    testing_padded = np.array(testing_padded)\n","    testing_labels = np.array(testing_labels)\n","\n","\n","    model = tf.keras.Sequential([\n","        tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n","        tf.keras.layers.GlobalAveragePooling1D(),\n","        tf.keras.layers.Dense(24, activation='relu'),\n","        tf.keras.layers.Dense(1, activation='sigmoid')])\n","\n","\n","    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n","\n","    model.summary()\n","\n","    num_epochs = 50\n","    history = model.fit(training_padded, training_labels, epochs=num_epochs, validation_data=(testing_padded, testing_labels), verbose=2)\n","\n","    return model\n","\n","\n","# Note that you'll need to save your model as a .h5 like this.\n","# When you press the Submit and Test button, your saved .h5 model will\n","# be sent to the testing infrastructure for scoring\n","# and the score will be returned to you.\n","if __name__ == '__main__':\n","    model = solution_model()\n","    model.save(\"mymodel.h5\")\n"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Model: \"sequential_10\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_10 (Embedding)     (None, 120, 16)           16000     \n","_________________________________________________________________\n","global_average_pooling1d_9 ( (None, 16)                0         \n","_________________________________________________________________\n","dense_21 (Dense)             (None, 24)                408       \n","_________________________________________________________________\n","dense_22 (Dense)             (None, 1)                 25        \n","=================================================================\n","Total params: 16,433\n","Trainable params: 16,433\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/50\n","625/625 - 1s - loss: 0.6785 - accuracy: 0.5620 - val_loss: 0.6438 - val_accuracy: 0.5736\n","Epoch 2/50\n","625/625 - 1s - loss: 0.5250 - accuracy: 0.7492 - val_loss: 0.4528 - val_accuracy: 0.7885\n","Epoch 3/50\n","625/625 - 1s - loss: 0.4159 - accuracy: 0.8112 - val_loss: 0.4166 - val_accuracy: 0.8100\n","Epoch 4/50\n","625/625 - 1s - loss: 0.3881 - accuracy: 0.8232 - val_loss: 0.4239 - val_accuracy: 0.7971\n","Epoch 5/50\n","625/625 - 1s - loss: 0.3756 - accuracy: 0.8302 - val_loss: 0.4022 - val_accuracy: 0.8162\n","Epoch 6/50\n","625/625 - 1s - loss: 0.3693 - accuracy: 0.8314 - val_loss: 0.4066 - val_accuracy: 0.8085\n","Epoch 7/50\n","625/625 - 1s - loss: 0.3627 - accuracy: 0.8356 - val_loss: 0.4122 - val_accuracy: 0.8046\n","Epoch 8/50\n","625/625 - 1s - loss: 0.3577 - accuracy: 0.8371 - val_loss: 0.4062 - val_accuracy: 0.8149\n","Epoch 9/50\n","625/625 - 1s - loss: 0.3579 - accuracy: 0.8371 - val_loss: 0.4020 - val_accuracy: 0.8167\n","Epoch 10/50\n","625/625 - 1s - loss: 0.3562 - accuracy: 0.8388 - val_loss: 0.4071 - val_accuracy: 0.8144\n","Epoch 11/50\n","625/625 - 1s - loss: 0.3531 - accuracy: 0.8404 - val_loss: 0.4023 - val_accuracy: 0.8158\n","Epoch 12/50\n","625/625 - 1s - loss: 0.3517 - accuracy: 0.8413 - val_loss: 0.4053 - val_accuracy: 0.8146\n","Epoch 13/50\n","625/625 - 1s - loss: 0.3513 - accuracy: 0.8421 - val_loss: 0.4083 - val_accuracy: 0.8097\n","Epoch 14/50\n","625/625 - 1s - loss: 0.3500 - accuracy: 0.8419 - val_loss: 0.4099 - val_accuracy: 0.8094\n","Epoch 15/50\n","625/625 - 1s - loss: 0.3495 - accuracy: 0.8416 - val_loss: 0.4054 - val_accuracy: 0.8110\n","Epoch 16/50\n","625/625 - 1s - loss: 0.3486 - accuracy: 0.8404 - val_loss: 0.4275 - val_accuracy: 0.8024\n","Epoch 17/50\n","625/625 - 1s - loss: 0.3490 - accuracy: 0.8414 - val_loss: 0.4094 - val_accuracy: 0.8103\n","Epoch 18/50\n","625/625 - 1s - loss: 0.3481 - accuracy: 0.8415 - val_loss: 0.4073 - val_accuracy: 0.8114\n","Epoch 19/50\n","625/625 - 1s - loss: 0.3477 - accuracy: 0.8407 - val_loss: 0.4075 - val_accuracy: 0.8129\n","Epoch 20/50\n","625/625 - 1s - loss: 0.3490 - accuracy: 0.8399 - val_loss: 0.4170 - val_accuracy: 0.8055\n","Epoch 21/50\n","625/625 - 1s - loss: 0.3475 - accuracy: 0.8414 - val_loss: 0.4079 - val_accuracy: 0.8134\n","Epoch 22/50\n","625/625 - 1s - loss: 0.3476 - accuracy: 0.8418 - val_loss: 0.4086 - val_accuracy: 0.8143\n","Epoch 23/50\n","625/625 - 1s - loss: 0.3473 - accuracy: 0.8432 - val_loss: 0.4143 - val_accuracy: 0.8098\n","Epoch 24/50\n","625/625 - 1s - loss: 0.3468 - accuracy: 0.8425 - val_loss: 0.4129 - val_accuracy: 0.8114\n","Epoch 25/50\n","625/625 - 1s - loss: 0.3488 - accuracy: 0.8414 - val_loss: 0.4225 - val_accuracy: 0.8040\n","Epoch 26/50\n","625/625 - 1s - loss: 0.3476 - accuracy: 0.8408 - val_loss: 0.4088 - val_accuracy: 0.8110\n","Epoch 27/50\n","625/625 - 1s - loss: 0.3467 - accuracy: 0.8421 - val_loss: 0.4088 - val_accuracy: 0.8128\n","Epoch 28/50\n","625/625 - 1s - loss: 0.3451 - accuracy: 0.8436 - val_loss: 0.4095 - val_accuracy: 0.8114\n","Epoch 29/50\n","625/625 - 1s - loss: 0.3466 - accuracy: 0.8419 - val_loss: 0.4102 - val_accuracy: 0.8129\n","Epoch 30/50\n","625/625 - 1s - loss: 0.3460 - accuracy: 0.8411 - val_loss: 0.4091 - val_accuracy: 0.8101\n","Epoch 31/50\n","625/625 - 1s - loss: 0.3462 - accuracy: 0.8435 - val_loss: 0.4089 - val_accuracy: 0.8120\n","Epoch 32/50\n","625/625 - 1s - loss: 0.3453 - accuracy: 0.8451 - val_loss: 0.4143 - val_accuracy: 0.8110\n","Epoch 33/50\n","625/625 - 1s - loss: 0.3464 - accuracy: 0.8414 - val_loss: 0.4082 - val_accuracy: 0.8111\n","Epoch 34/50\n","625/625 - 1s - loss: 0.3456 - accuracy: 0.8430 - val_loss: 0.4104 - val_accuracy: 0.8125\n","Epoch 35/50\n","625/625 - 1s - loss: 0.3467 - accuracy: 0.8419 - val_loss: 0.4233 - val_accuracy: 0.8088\n","Epoch 36/50\n","625/625 - 1s - loss: 0.3458 - accuracy: 0.8421 - val_loss: 0.4095 - val_accuracy: 0.8120\n","Epoch 37/50\n","625/625 - 1s - loss: 0.3454 - accuracy: 0.8439 - val_loss: 0.4099 - val_accuracy: 0.8111\n","Epoch 38/50\n","625/625 - 1s - loss: 0.3448 - accuracy: 0.8442 - val_loss: 0.4184 - val_accuracy: 0.8059\n","Epoch 39/50\n","625/625 - 1s - loss: 0.3463 - accuracy: 0.8431 - val_loss: 0.4161 - val_accuracy: 0.8067\n","Epoch 40/50\n","625/625 - 1s - loss: 0.3452 - accuracy: 0.8425 - val_loss: 0.4183 - val_accuracy: 0.8049\n","Epoch 41/50\n","625/625 - 1s - loss: 0.3449 - accuracy: 0.8417 - val_loss: 0.4109 - val_accuracy: 0.8135\n","Epoch 42/50\n","625/625 - 1s - loss: 0.3436 - accuracy: 0.8439 - val_loss: 0.4180 - val_accuracy: 0.8047\n","Epoch 43/50\n","625/625 - 1s - loss: 0.3448 - accuracy: 0.8433 - val_loss: 0.4088 - val_accuracy: 0.8132\n","Epoch 44/50\n","625/625 - 1s - loss: 0.3449 - accuracy: 0.8446 - val_loss: 0.4086 - val_accuracy: 0.8125\n","Epoch 45/50\n","625/625 - 1s - loss: 0.3438 - accuracy: 0.8453 - val_loss: 0.4102 - val_accuracy: 0.8123\n","Epoch 46/50\n","625/625 - 1s - loss: 0.3430 - accuracy: 0.8447 - val_loss: 0.4140 - val_accuracy: 0.8070\n","Epoch 47/50\n","625/625 - 1s - loss: 0.3439 - accuracy: 0.8447 - val_loss: 0.4324 - val_accuracy: 0.8058\n","Epoch 48/50\n","625/625 - 1s - loss: 0.3450 - accuracy: 0.8439 - val_loss: 0.4115 - val_accuracy: 0.8123\n","Epoch 49/50\n","625/625 - 1s - loss: 0.3435 - accuracy: 0.8449 - val_loss: 0.4092 - val_accuracy: 0.8098\n","Epoch 50/50\n","625/625 - 1s - loss: 0.3425 - accuracy: 0.8429 - val_loss: 0.4089 - val_accuracy: 0.8132\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"g53MauP06Tnf","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}